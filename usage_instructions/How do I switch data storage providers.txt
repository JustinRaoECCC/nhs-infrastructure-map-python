===========================
Using a New Data Storage Provider
===========================

What‚Äôs happening right now?
---------------------------
**Excel mode (default: USE_DATABASE=false)**

- All lookups and station sheets live under:  
  `data/locations/`

- One file per Location:  
  `data/locations/<Location>.xlsx`

- One sheet per Asset Type inside each location workbook

- Adding a new Location automatically creates `<Location>.xlsx`  
  with sheets for every existing asset type

- Adding a new Asset Type automatically appends a new sheet  
  to every location workbook

**SQL mode (USE_DATABASE=true)**

- Backed by SQLAlchemy using `DB_URL`  
  (default: `sqlite:///data/app.db`)

- All data lives in one SQLite file (or your chosen DB) with tables:  
  `companies`, `locations`, `asset_types`, `stations`, `repairs`, `sections`

- On reads and writes, DataManager lazy-migrates any Excel lookups  
  (`locations` & `asset types`) into SQL so the two stay in sync

- To use Postgres/MySQL, override `DB_URL` (see below)


Read the Persistence Interface
------------------------------
Open `backend/persistence.py`. You'll find:

```python
class BaseRepo(ABC):
    def get_locations()
    def add_location(name)
    def get_asset_types()
    def add_asset_type(name)
    def list_stations()
    def create_station(station_obj)
    def save_repair(station_id, repair_obj)
    def save_sections(station_id, sections)
    def get_sections_for_station(station_id)


Implementing a Custom Storage Provider
======================================

Every new storage backend must implement the full `BaseRepo` interface.

Step 1: Create Your Provider Stub
---------------------------------
In the `backend/` folder, create a new file, for example:  
`myrepo.py`

**Import the abstract base class:**
```python
from .persistence import BaseRepo

mplement the Full Interface
----------------------------
In your `myrepo.py`, define a class that implements all methods from `BaseRepo`.

Example:
```python
from .persistence import BaseRepo

class MyRepo(BaseRepo):
    def get_locations(self) -> list[str]:
        # Return a list of location names
        ...

    def add_location(self, name: str) -> dict:
        # Add a new location and return its record
        ...

    def get_asset_types(self) -> list[str]:
        # Return a list of asset type names
        ...

    def add_asset_type(self, name: str) -> dict:
        # Add a new asset type and return its record
        ...

    def list_stations(self) -> list[dict]:
        # Return all station records
        ...

    def create_station(self, station_obj: dict) -> dict:
        # Create a new station and return it
        ...

    def save_repair(self, station_id: int, repair_obj: dict) -> None:
        # Save repair data for the given station
        ...

    def save_sections(self, station_id: int, sections: list[dict]) -> None:
        # Save section data for the given station
        ...

    def get_sections_for_station(self, station_id: int) -> list[dict]:
        # Return the sections for the given station
        ...


You're free to use any tools or libraries inside your implementation ‚Äî  
SQL clients, file system utilities, REST APIs, in-memory caches ‚Äî whatever suits your backend.

Step 2: Wire It Into DataManager
--------------------------------
By default, `DataManager` uses both Excel and SQL providers under the hood:

```python
# backend/data_manager.py

dm = DataManager()  # Uses ExcelRepo + DBRepo internally

Step 2: Use Your Custom Provider
-------------------------------
To fully replace both Excel and SQL backends with your own implementation, update `data_manager.py` like this:

```python
from .data_manager import DataManager
from .myrepo       import MyRepo

dm = DataManager(
    excel_provider=MyRepo(),
    db_provider=MyRepo()
)

Combining Your Provider with an Existing One
--------------------------------------------
You can mix and match providers ‚Äî for example, keep Excel for lookups but use your custom repo for SQL:

```python
from .excel_repo import ExcelRepo
from .myrepo     import MyRepo

dm = DataManager(
    excel_provider=ExcelRepo(),
    db_provider=MyRepo()
)

‚úÖ Your existing @eel.expose handlers don‚Äôt need to be changed ‚Äî everything continues to work automatically.

Step 3: Choose the Active Read Backend
--------------------------------------
You control which backend handles reads (`get_*()` calls) by configuring `backend/config.py`:

```python
# backend/config.py

# Set to False to use Excel (.xlsx) files under data/locations/
# Set to True to use a SQL database via DB_URL
USE_DATABASE = False
DB_URL = "sqlite:///data/app.db"

Behavior Summary
----------------
- `USE_DATABASE = False` ‚Üí All `get_*()` calls are handled by `ExcelRepo`
- `USE_DATABASE = True`  ‚Üí All `get_*()` calls are handled by `DBRepo`

üìù Note: Regardless of mode, **write operations always go to both** providers to keep them in sync.


Step 4: Verify & Test Your Setup
--------------------------------
1. Save all code changes.
2. Select your backend mode via `backend/config.py` or environment variables.
3. Launch the application:

```bash
python run.py

‚úî If running in Excel mode:
----------------------------
- `.xlsx` files will be created under `data/locations/`
- Each asset type will appear as a separate sheet inside the corresponding location workbook

‚úî If running in SQL mode:
--------------------------
- Open `data/app.db` or connect to your configured SQL database
- Verify that the following tables exist and contain data:
  - `locations`
  - `asset_types`
  - `stations`
  - (plus any other tables your schema requires)

‚úÖ With this modular setup, you can freely switch between Excel and SQL storage at any time ‚Äî  
without changing your UI, Eel handlers, or front-end logic.
